# Asistente Tec-IA

## Descripci√≥n del Proyecto

**Asistente Tec-IA** es una aplicaci√≥n de asistente virtual desarrollada como trabajo integrador de la carrera de **Tecnicatura Superior en Ciencia de Datos e IA** del **IFTS 24**. Esta herramienta est√° dise√±ada para apoyar a los estudiantes en su proceso de aprendizaje mediante m√∫ltiples funcionalidades basadas en inteligencia artificial.

## Caracter√≠sticas Principales

### ü§ñ Chatbot Inteligente
- Asistente virtual alimentado por una base de datos custom cargada con informaci√≥n espec√≠fica de la carrera y las materias
- Responde consultas relacionadas con el contenido acad√©mico
- Interfaz conversacional intuitiva

### üìÑ Resumidor de Textos
- Capacidad para resumir archivos de texto de hasta **1200 palabras**
- Utiliza el modelo de **ollama-llama3.2** de Meta (`llama3.2:latest`)
- Genera res√∫menes concisos y coherentes

### üîç Extractor de Palabras Clave
- Identificaci√≥n autom√°tica de palabras clave en textos
- Implementado con **KeyBERT**
- Ayuda a identificar los conceptos m√°s relevantes de un documento

### ‚ùì M√≥dulo de Preguntas Frecuentes (FAQ)
- Sistema de preguntas frecuentes para acelerar las respuestas
- B√∫squeda inteligente en base a las consultas del usuario
- Crea una base de conocimiento interactiva para que los estudiantes pongan a prueba sus conocimientos

## Requisitos del Sistema

### Software Necesario
- **Python 3.10+** (desarrollado en Python 3.10)
- **Ollama** con el modelo **Llama 3.2**
- **Git** para clonar el repositorio
- **Conda** (recomendado para gesti√≥n de entornos)

### Sistemas Operativos Compatibles
- Windows 10/11
- Linux (Ubuntu, Debian, CentOS, etc.)

## Instalaci√≥n

### 1. Clonar el Repositorio
```bash
git clone git@github.com:parivgabriela/Proyecto_Integrador.git
cd asistente-tec-ia
```

### 2. Instalar Ollama y el Modelo Llama 3.2

#### Para Windows:
1. Descargar Ollama desde: https://ollama.com/download
2. Instalar el ejecutable
3. Abrir terminal y ejecutar:
```bash
ollama run llama3.2
```

#### Para Linux:
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama run llama3.2
```

### 3. Crear Entorno Virtual con Conda
Puede ser otro entorno

```bash
conda create --name asistente-tec-ia python=3.10
conda activate asistente-tec-ia
```

### 4. Instalar Dependencias

```bash
pip install -r requirements.txt
```

## Ejecuci√≥n de la Aplicaci√≥n

### Windows
Ejecutar el archivo por lotes incluido:
```bash
start.bat
```

### Linux
Ejecutar el script shell:
```bash
chmod +x start.sh
./start.sh
```

### Ejecuci√≥n Manual
Si prefieres ejecutar manualmente:
```bash
conda activate asistente-tec-ia
python3 run.py
```

## Estructura del Proyecto

```
Proyecto_Integrador      
‚îú‚îÄ‚îÄ asistente-tec-ia/
    ‚îú‚îÄ‚îÄ app/                  # Aplicaci√≥n principal
    ‚îú‚îÄ‚îÄ start.bat             # Script de inicio para Windows
    ‚îú‚îÄ‚îÄ start.sh              # Script de inicio para Linux
    ...          
‚îî‚îÄ‚îÄ README.md                 # Archivo Readme
```

## Uso de la Aplicaci√≥n

### Chatbot
1. Inicia la aplicaci√≥n
2. Escribe tu consulta en el chat
3. El asistente responder√° bas√°ndose en la base de datos de la carrera

### Resumidor de Textos
1. Selecciona la opci√≥n "Resumir Texto"
2. Carga tu archivo de texto (m√°ximo 1200 palabras)
3. Obt√©n un resumen conciso del contenido

### Extractor de Palabras Clave
1. Accede a la funci√≥n "Palabras Clave"
2. Ingresa o carga tu texto
3. Visualiza las palabras clave m√°s relevantes

### Preguntas Frecuentes
1. Navega al m√≥dulo de FAQ
2. Explora las preguntas frecuentes disponibles
3. Pon a prueba tu conocimiento respondiendo las preguntas

## Soluci√≥n de Problemas

### Error: "Ollama not found"
- Verifica que Ollama est√© instalado y en el PATH del sistema
- Aseg√∫rate de que el modelo Llama 3.2 est√© descargado

### Error: "Module not found"
- Verifica que el entorno virtual est√© activado
- Reinstala las dependencias: `pip install -r requirements.txt`

### Problemas con CUDA (Linux)
- Si tienes GPU NVIDIA, instala los drivers apropiados
- Para CPU √∫nicamente, las dependencias funcionar√°n sin configuraci√≥n adicional

## Contribuci√≥n

Este proyecto fue desarrollado como trabajo integrador acad√©mico. Para contribuciones:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'A√±ade nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## Autores

- **Gabriela Juliana Pari Vaca**
- **IFTS 24**

## Contacto

databypari@gmail.com

---

*Desarrollado con ‚ù§Ô∏è y mucha paciencia*

